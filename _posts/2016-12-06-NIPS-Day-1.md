---
layout: post
title: NIPS Day I
published: true
---

Since there's so much happening at NIPS on a daily basis, I thought it'll be
easier and better for me to table my thoughts and learnings in a post each day.

*Disclaimer: I'm a distributed systems engineer who's now interfacing with Machine learning teams.
This is why my theoretical understanding of Machine Learning is novice at best.*

##Tutorial I: Crowdsourcing beyond label generation
This was the first session by [Jenn Wortman](http://www.jennwv.com/).
It revolved around some salient points around managing the network.

Some of the direct applications of crowd sourcing are:
* Evaluating topic models. This is especially useful for data exploration and human interpretable summarization of text/audio/video.
* Human debugging of machine learning models. Useful to figure out the weak spots in the data pipeline.
If there's a huge error between human performance and machine performance, that's the step to focus on.
* Human clustering of data. The main idea here is to divide the dataset into multiple sections
and give them to multiple people with overlapping. The results are then aggregated using bayesian models.

Crowd-sourcing can also be effective while building Hybrid Intelligence Systems (human in the loop):
* A sample use-case is close captioning of audio in near realtime. The audio is split into multiple pieces
and distributed to a network of workers. As earlier, the results are collated and
aggregated before being displayed back to the user.
* Community sourced scheduling. [Project Cobi](http://projectcobi.com) gets humans to help the
machine identify constraints within a system. The machine then spits out a schedule based on those constraints.
* Information aggregation can be modelled as a stock market prediction of people's beliefs.
[Predictit](predictit.org) was doing this during the USA elections recently.

Social behaviour analysis of humans is a very interesting application of crowd sourcing.
In the past these studies have helped us identify better representations of numerals and find
the cost of bad online advertisements and spam.

### How to manage the crowd
#### Monetary Incentives
One of the first things to do while planning to pay workers is to pilot the task with
your team, colleagues & peers. This helps benchmark the difficulty & time of the task.
Once that is done, pay at least USA minimum wage.

**Do performance based payments work?**
Short answer: It depends. If the task is effort responsive (more time leads to better results)
then yes, else no. Unfortunately, it's not easy to figure out which task is effort responsive.

#### Intrinsic Motivation
Meaningful work leads to more quantity of work done by workers but not quality.

#### Communication Networks
It's incorrect to assume that crowd workers don't communicate. There are multiple external
forums that workers can use to communicate. Also, connected workers find work faster and also produce better results.

#### Best Practices
* Maintain good relationship with workers
* Respond to questions quickly
* Approve work quickly
* Avoid rejecting work unless extreme
* Pilot heavily with co-workers & collaborators
* Iterate the task N times
* Create clear instructions. Can include quiz questions if required.
* Create easy-to-use interface. Pilot this as well!
* Ask workers for feedback & bugs. Conduct exit surveys
